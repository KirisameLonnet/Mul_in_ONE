# Database Migration Guide

This document explains how to move an existing Mul-in-One deployment to the new PostgreSQL-backed storage for sessions, API profiles, and personas.

## 1. Configure the environment

1. Choose a PostgreSQL instance (local Docker container or managed service).
2. Export the connection information so every process uses the same database URL:
   ```bash
   export DATABASE_URL="postgresql+asyncpg://<user>:<password>@<host>:5432/mul_in_one"
   export MUL_IN_ONE_SESSION_REPO="db"
   ```
3. (Optional) set the runtime mode if you want to use the real NeMo runtime:
   ```bash
   export MUL_IN_ONE_RUNTIME_MODE="nemo"
   export MUL_IN_ONE_ENCRYPTION_KEY="<32+ char secret for API keys>"
   ```

## 2. Run Alembic migrations

All schema changes live in `alembic/`. From the repository root:

```bash
alembic upgrade head
```

This command applies the baseline migration (`20240722_0001_initial_schema.py`) and creates the following tables:

- `tenants`
- `users`
- `api_profiles`
- `personas`
- `sessions`
- `session_messages`

### Creating new migrations

When you make schema changes:

```bash
alembic revision --autogenerate -m "short description"
alembic upgrade head
```

If the autogenerated diff looks inaccurate, edit the generated file before running `upgrade`.

## 3. Seed API profiles and personas

After the schema exists you can populate it either through the FastAPI endpoints or a custom script.

### Using the REST API

1. Start the backend service:
   ```bash
   uvicorn mul_in_one_nemo.service.app:create_app --host 0.0.0.0 --port 8000 --reload
   ```
2. Create API profiles:
   ```bash
   curl -X POST http://localhost:8000/api/api-profiles \
        -H "Content-Type: application/json" \
        -d '{
              "tenant_id": "default",
              "name": "nim-default",
              "base_url": "https://integrate.api.nvidia.com/v1",
              "model": "meta/llama-3.1-70b-instruct",
              "api_key": "sk-xxxx",
              "temperature": 0.4
            }'
   ```
3. Create personas that reference the profile IDs returned above:
   ```bash
   curl -X POST http://localhost:8000/api/personas \
        -H "Content-Type: application/json" \
        -d '{
              "tenant_id": "default",
              "name": "技术专家",
              "prompt": "你是一个博学的技术专家",
              "tone": "confident",
              "proactivity": 0.7,
              "api_profile_id": 1,
              "is_default": true
            }'
   ```

### Importing from the legacy YAML

1. Keep your existing `personas/persona.yaml` and `personas/api_configuration.yaml` files.
2. Write a one-off script that uses `mul_in_one_nemo.persona.load_personas` and `mul_in_one_nemo.api_config.load_api_configuration` to read the YAML, then call the same REST endpoints (or the new repository classes) to save the data.
3. Once the data is stored in Postgres you can remove or archive the YAML files.

## 4. Verifying the migration

- Run `pytest tests/test_service_persona_repository.py tests/test_service_persona_routes.py` to ensure the repository layer works.
- Hit `GET /api/api-profiles?tenant_id=<tenant>` and `GET /api/personas?tenant_id=<tenant>` to confirm the frontend can retrieve the new records.
- Start a conversation with the backend service; the runtime adapter now loads personas from the database per tenant.

Following these steps ensures all persona metadata and API keys live in PostgreSQL, protected by the configured encryption key and ready for the frontend management UI.
